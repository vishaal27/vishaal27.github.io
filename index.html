<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <!-- Hi, Jon Here. Please DELETE the two <script> tags below if you use this HTML, otherwise my analytics will track your page -->
  <!-- Global site tag (gtag.js) - Google Analytics -->

  <title>Vishaal Udandarao</title>
  
  <meta name="author" content="Vishaal Udandarao">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/v_.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Vishaal Udandarao</name>
              </p>
              <p>I am a second year <a href="https://ellis.eu/phd-postdoc">ELLIS</a> PhD student, jointly working with <a href="https://scholar.google.de/citations?user=0z0fNxUAAAAJ&hl=en">Matthias Bethge</a> at <a href="https://bethgelab.org/">The University of Tuebingen</a> and <a href="http://samuelalbanie.com/">Samuel Albanie</a> at <a href="https://mi.eng.cam.ac.uk/">The University of Cambridge</a>. I am also a part of the <a href="https://imprs.is.mpg.de/">International Max Planck Research School for Intelligent Systems</a>. I am mainly interested in understanding the generalisation properties of foundation models, both LLMs and large multi-modal models (LMMs), through the lens of data. 
              </p>
              <p>
                Previously, I was an <a href="https://www.mlmi.eng.cam.ac.uk/">MPhil Machine Learning and Machine Intelligence</a> student at The University of Cambridge. My thesis was on <a href="https://www.mlmi.eng.cam.ac.uk/files/2021-2022_dissertations/understanding_and_fixing_the_modality_gap_in_vision-language_models_reduced.pdf">Understanding and Fixing the Modality Gap in VLMs</a>. I graduated from <a href="http://iiitd.ac.in/">IIIT Delhi</a> with a B.Tech in Computer Science & Engineering in July, 2020.
              </p>
              <p>
                I am also fortunate to have previously worked with several great mentors: <a href="https://ankushgupta.org/">Ankush Gupta (Google Deepmind)</a>, <a href="https://sungjinahn.com/">Sungjin Ahn (KAIST)</a>, <a href="http://faculty.iiitd.ac.in/~tanmoy/">Tanmoy Chakraborty (IIT Delhi)</a>, <a href="https://www.iiitd.edu.in/~rajivratn/">Rajiv Ratn Shah (IIIT Delhi)</a>, <a href="https://faculty.iiitd.ac.in/~anands/">Saket Anand (IIIT Delhi)</a>, <a href="https://sites.google.com/view/kumar7">Rajesh Kumar (Bucknell University)</a>, <a href="https://www.iiitd.edu.in/~anubha/">Anubha Gupta (IIIT Delhi)</a> and <a href="https://www.iiitd.ac.in/jainendra">Jainendra Shukla (IIIT Delhi)</a>.
              </p>
              
              <p style="text-align:center">
                <a href="mailto:vishaal16119@iiitd.ac.in">Email</a> &nbsp/&nbsp
                <a href="data/Vishaal_CV%20(3).pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=jUOcawkAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/vishaal_urao">Twitter</a> &nbsp/&nbsp
                <a href="https://github.com/vishaal27">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/IMG_4009.jpeg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/IMG_4009.jpeg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody> 

            <tr>
<!--             <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/sus-x_sq.jpg" alt="sus-x" width="250" height="250">
            </td> -->
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2310.08577">
                <papertitle>Visual Data-Type Understanding does not emerge from Scaling Vision-Language Models</papertitle>
              </a>
              <br>
              <strong>Vishaal Udandarao*</strong>, <a href="https://scholar.google.de/citations?user=-T_5tc0AAAAJ&hl=en">Max F. Burg*</a>, <a href="samuelalbanie.com">Samuel Albanie</a>, <a href="https://scholar.google.com/citations?user=0z0fNxUAAAAJ">Matthias Bethge</a>
              <br>
              <em>Arxiv</em>, 2023
              <br>
              <a href="https://arxiv.org/pdf/2310.08577.pdf">pdf</a> /
              <a href="https://github.com/bethgelab/DataTypeIdentification">code</a>
              <p>We introduce "Visual Data-Type Identification": the task of classifying between visual image distortions and styles. On this simple task, we find surprising behaviour of VLMs and LMMs: model scaling does not significantly improve performance. We trace this behaviour back to the LAION-2B dataset and show a simple fine-tuning method to improve performance.</p>
            </td>
          </tr>
          
            <tr>
<!--             <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/sus-x_sq.jpg" alt="sus-x" width="250" height="250">
            </td> -->
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2211.16198">
                <papertitle>SuS-X: Training-Free Name-Only Transfer of Vision-Language Models</papertitle>
              </a>
              <br>
              <strong>Vishaal Udandarao</strong>, <a href="https://ankushgupta.org/">Ankush Gupta</a>, <a href="samuelalbanie.com">Samuel Albanie</a>
              <br>
              <em>ICCV</em>, 2023
              <br>
              <a href="https://arxiv.org/pdf/2211.16198.pdf">pdf</a> /
              <a href="https://github.com/vishaal27/sus-X/">code</a>
              <p>We enhance CLIP's downstream classification performance by (1) curating a support set either by generating synthetic (Stable Diffusion) or retrieving natural (LAION-5B) samples, and (2) observing and fixing a mis-calibration issue with intra-modal distances in CLIPâ€™s embedding space.</p>
            </td>
          </tr>
          
            <tr>
<!--             <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/levasa_sq.jpg" alt="levasa" width="250" height="250">
            </td> -->
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2007.10058">
                <papertitle>It's LeVAsa not LevioSA! Latent Encodings for Valence-Arousal Structure Alignment</papertitle>
              </a>
              <br>
              <strong>Vishaal Udandarao*</strong>, <a href="https://surabhisnath.github.io/index.html">Surabhi Nath*</a>, <a href="https://jainendra.in/">Jainendra Shukla</a>
              <br>
              <em>CODS-COMAD</em>, 2021
              <br>
              <a href="https://arxiv.org/pdf/2007.10058.pdf">pdf</a> /
              <a href="https://github.com/vishaal27/LeVAsa">code</a>
              <p>A VAE model that learns implicit structure by aligning the latent space with the Valence-Arousal circumplex space. Further, a novel algorithm for mapping categorical and dimensional model labels using annotation transfer across affective facial image datasets is depicted.</p>
            </td>
          </tr>
          
          <tr>
<!--             <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/cobra_sq.jpg" alt="cobra" width="250" height="250">
            </td> -->
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2005.03687">
                <papertitle>COBRA: Contrastive Bi-Modal Representation Algorithm</papertitle>
              </a>
              <br>
              <strong>Vishaal Udandarao*</strong>, <a href="http://ovshake.me/">Abhishek Maiti*</a>, <a href="https://suryatejreddy.github.io/">Suryatej Reddy Vyalla*</a>, <a href="https://scholar.google.com/citations?user=DlLbu9UAAAAJ&hl=en">Deepak Srivatsav*</a>, <a href="https://scholar.google.com.sg/citations?user=TRfTdBAAAAAJ&hl=en">Yifang Yin</a>, <a href="https://www.iiitd.edu.in/~rajivratn/">Rajiv Ratn Shah</a>
              <br>
              <em>TUSION workshop, IJCAI</em>, 2020
              <br>
              <a href="https://arxiv.org/pdf/2005.03687.pdf">pdf</a> /
              <a href="https://github.com/ovshake/cobra">code</a>
              <p>A novel bi-modal framework that aims to train two modalities (image and text) in a joint fashion inspired by the Contrastive Predictive Coding (CPC) and Noise Contrastive Estimation (NCE) paradigms which preserve both inter and intra-class relationships in a modality-invariant fashion.</p>
            </td>
          </tr>   

          
           <tr>
<!--             <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/inphynet_sq.jpg" alt="inphynet" width="250" height="250">
            </td> -->
            <td width="75%" valign="middle">
              <a href="https://www.sciencedirect.com/science/article/abs/pii/S095070512030616X">
                <papertitle>InPHYNet: Leveraging Attention-based Multitask Recurrent Networks for Multi-label Physics Text Classification</papertitle>
              </a>
              <br>
              <strong>Vishaal Udandarao*</strong>, Abhishek Agarwal*, <a href="https://www.iiitd.edu.in/~anubha/">Anubha Gupta</a>, <a href="http://faculty.iiitd.ac.in/~tanmoy/">Tanmoy Chakraborty</a>
              <br>
              <em>Knowledge-Based Systems</em>, 2020
              <br>
              <a href="https://www.sciencedirect.com/science/article/abs/pii/S095070512030616X">pdf</a> /
              <a href="https://github.com/abhishekag03/InPHYNet">code</a>
              <p>A multi-task learning model which incorporates auxiliary semantics by utilising a weight alignment layer and information exchange layer.</p>
            </td>
          </tr>
          
           <tr>
<!--             <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/discont_sq.jpg" alt="discont" width="250" height="250">
            </td> -->
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2006.05895">
                <papertitle>DisCont: Self-Supervised Visual Attribute Disentanglement using Context Vectors</papertitle>
              </a>
              <br>
              <strong>Vishaal Udandarao*</strong>, <a href="https://sarthak268.github.io/">Sarthak Bhagat*</a>, <a href="https://shagunuppal.github.io/">Shagun Uppal*</a>, <a href="https://faculty.iiitd.ac.in/~anands/">Saket Anand</a>
              <br>
              <em>PTSGM Workshop, ECCV</em>, 2020, <em>MLI4SD Workshop, ICML</em>, 2020
              <br>
              <a href="https://arxiv.org/pdf/2006.05895.pdf">pdf</a> /
              <a href="https://sarthak268.github.io/discont/">project page</a> /
              <a href="https://docs.google.com/presentation/d/1Qa3DiLQiJ_JpPk2Nx1v4QmcjIx5AsESNbZLUJ8rmD8A/edit">slides</a> /
              <a href="https://www.youtube.com/watch?v=lIYCMHesVBw&feature=youtu.be">video</a> /
              <a href="https://github.com/sarthak268/DisCont">code</a>
              <p>A self-supervised framework to disentangle multiple attributes by exploiting structural inductive biases within images and leveraging contrastive learning paradigms.</p>
            </td>
          </tr>

           <tr>
<!--             <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/privacy-leaks_sq.jpg" alt="privacy-leak" width="250" height="250">
            </td> -->
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2006.09501">
                <papertitle>On the Inference of Soft Biometrics from Typing Patterns Collected in a Multi-device Environment</papertitle>
              </a>
              <br>
              <strong>Vishaal Udandarao*</strong>, <a href="https://sites.google.com/view/mohit-agrawal/home/">Mohit Agrawal*</a>, <a href="https://sites.google.com/view/kumar7">Rajesh Kumar</a>, <a href="https://www.iiitd.edu.in/~rajivratn/">Rajiv Ratn Shah</a>
              <br>
              <em>BigMM</em>, 2020
              <br>
              <a href="https://conferences.computer.org/bigmm/pdfs/BigMM2020-13PaMgtIXlZNQOagcn4uc7/932500a076/932500a076.pdf">pdf</a> /
              <a href="https://github.com/midas-research/privacy-leaks">code</a>
              <p>An empirical study on the inference of gender, major/minor (computer science, non-computer science), typing style, age, and height from the typing patterns collected from 117 individuals in a multi-device environment.</p>
            </td>
          </tr>          
          
           <tr>
<!--             <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/memeify_sq.jpg" alt="memeify" width="250" height="250">
            </td> -->
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/1910.12279">
                <papertitle>Memeify: A Large-Scale Meme Generation System</papertitle>
              </a>
              <br>
              <strong>Vishaal Udandarao*</strong>, <a href="https://suryatejreddy.github.io/">Suryatej Reddy Vyalla*</a>, <a href="http://faculty.iiitd.ac.in/~tanmoy/">Tanmoy Chakraborty</a>
              <br>
              <em>CODS-COMAD</em>, 2020
              <br>
              <a href="https://arxiv.org/pdf/1910.12279.pdf">pdf</a> /
              <a href="https://docs.google.com/presentation/d/1-u7WvZBYdiz2D1j08YGXPrvDiVSgDvJqb20KuY6Fs98/edit?usp=sharing">slides</a> /
              <a href="https://www.youtube.com/watch?v=P_Tfs0X-czs">video</a> /
              <a href="https://github.com/suryatejreddy/Memeify">code</a>
              <p>A meme generation system that uses a trained state-of-the-art transformer-based (GPT-2) model for caption generation by employing an encoder-decoder architecture.</p>
            </td>
          </tr>          
          
           <tr>
<!--             <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/eduqa_sq.jpg" alt="eduqa" width="250" height="250">
            </td> -->
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/1911.05013">
                <papertitle>EDUQA: Educational Domain Question Answering System using Conceptual Network Mapping</papertitle>
              </a>
              <br>
              <strong>Vishaal Udandarao*</strong>, Abhishek Agarwal*, Nikhil Sachdeva*, Raj Kamal Yadav*, Vrinda Mittal*, <a href="https://www.iiitd.edu.in/~anubha/">Anubha Gupta</a>, Abhinav Mathur
              <br>
              <em>ICASSP</em>, 2019
              <br>
              <a href="https://arxiv.org/pdf/1911.05013.pdf">pdf</a> /
              <a href="https://drive.google.com/file/d/1Gie8Os1v8OUUo6QV5c0oHYzIePMVIr4y/view?usp=sharing">poster</a>
              <p> An on-the-fly conceptual network model that incorporates educational semantics and preserves correlations between conceptual entities by applying intelligent indexing algorithms on an inherent concept network so as to improve answer generation.</p>
            </td>
          </tr>
          
           
         <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr> <td>
  <heading>Teaching</heading>
  </td> </tr> </table>
  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">

    <!-- project begin -->
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:top">
                <papertitle>Deep Learning (CSE641)</papertitle>
              <br/>
              Worked as a Teaching Assistant for the Deep Learning course offered by <a href="https://faculty.iiitd.ac.in/~anands/">Dr. Saket Anand</a> in Spring 2020.
            </td>
          </tr>
    <!-- project end -->

      
    <!-- project begin -->
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:top">
                <papertitle>Machine Learning (CSE543)</papertitle>
              <br/>
              Worked as a Teaching Assistant for the Machine Learning course offered by <a href="https://jainendra.in/">Dr. Jainendra Shukla</a> in Fall 2019.
            </td>
          </tr>
    <!-- project end -->
      
          <!-- project begin -->
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:top">
                <papertitle>Introduction to Engineering Design (DES130)</papertitle>
              <br/>
              Worked as a Teaching Assistant for the Introduction to Engineering Design course offered by <a href="https://amanparnami.com/">Dr. Aman Parnami</a> in Spring 2019.
            </td>
          </tr>
    <!-- project end -->
      
      
          <!-- project begin -->
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:top">
                <papertitle>Linear Algebra (MTH100)</papertitle>
              <br/>
              Worked as a Teaching Assistant for the Linear Algebra course offered by Dr. Samaresh Chatterjee in Fall 2018.
            </td>
          </tr>
    <!-- project end -->

         <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr> <td>
  <heading>Misc</heading>
  </td> </tr> </table>
  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
              <p>
                Apart from my academic interests, I am a huge football fan and actively support <s>FC Barcelona</s> <s>Paris Saint Germain</s> Inter Miami CF. Fun fact: Did you know Lionel Messi is the greatest player to ever touch a football? No? Well, deal with it. I also love watching Formula 1 and look up to Lewis Hamilton. I used to <a href="data/vishaal_poems.pdf">write</a> stuff, but that was a long long time ago. I also dabble around with the guitar and the keyboard at times. Checkout my <a href="https://soundcloud.com/vishaal-udandarao">soundcloud profile</a>!
              </p>
      
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
                Website template taken from <a href="https://github.com/jonbarron/website/">here</a>.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>      
</body>

</html>
